# DoD Budget CI Workflow (Step 4.B1-a)
#
# Runs on every push and pull request to main.
# Matrix: Python 3.11 and 3.12.
# Steps: lint/precommit checks, then pytest with coverage, mypy, Docker build.
# Fails the PR if any tests fail or precommit violations are found.

name: CI

on:
  push:
    branches: [main, "claude/**"]
  pull_request:
    branches: [main]

jobs:
  test:
    name: "Test (Python ${{ matrix.python-version }})"
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.11", "3.12"]

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install ruff pytest pytest-cov mypy pyyaml fpdf2

      - name: Lint with ruff
        run: |
          ruff check . --select=E,W,F --ignore=E501 --exclude=DoD_Budget_Documents
        continue-on-error: true   # Warn but don't fail on style issues

      # CI-002: mypy type checking
      - name: Type check with mypy
        run: |
          mypy api/ utils/ --ignore-missing-imports --no-error-summary
        continue-on-error: true   # Warn but don't fail until all stubs added

      # DONE [Group: BEAR] BEAR-006: Coverage threshold enforcement (80%) via pyproject.toml
      # DONE [Group: BEAR] BEAR-011: Performance profiling added as post-test step

      # CI-001: Run tests with coverage reporting
      # BEAR-006: --cov-fail-under=80 enforces minimum coverage threshold
      - name: Run tests with coverage
        run: |
          python -m pytest tests/ \
            --ignore=tests/test_gui_tracker.py \
            --cov=api --cov=utils \
            --cov-report=xml \
            --cov-report=term-missing \
            --cov-fail-under=80 \
            -v \
            --tb=short \
            -q

      # CI-001: Upload coverage report as artifact
      - name: Upload coverage report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.python-version }}
          path: coverage.xml
          retention-days: 7

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pytest-results-${{ matrix.python-version }}
          path: |
            .pytest_cache/
          retention-days: 7

      # BEAR-011: Performance profiling (runs after tests pass)
      - name: Run performance profiling
        run: python scripts/profile_queries.py --json
        continue-on-error: true   # Don't fail CI on perf regressions (yet)

      - name: Upload profiling report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: profiling-${{ matrix.python-version }}
          path: profile_report.json
          retention-days: 7

      - name: Performance summary
        if: always()
        run: |
          if [ -f profile_report.json ]; then
            echo "## Performance Profiling Results" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Query | Time (ms) | Threshold (ms) | Status |" >> $GITHUB_STEP_SUMMARY
            echo "|-------|-----------|----------------|--------|" >> $GITHUB_STEP_SUMMARY
            python -c "
          import json, sys
          try:
              with open('profile_report.json') as f:
                  data = json.load(f)
              for key, ms in data.get('timings', {}).items():
                  threshold = data.get('thresholds', {}).get(key, 500)
                  status = 'PASS' if ms <= threshold else 'FAIL'
                  print(f'| {key} | {ms:.0f} | {threshold} | {status} |')
          except Exception as e:
              print(f'Error reading profile: {e}', file=sys.stderr)
          " >> $GITHUB_STEP_SUMMARY
          fi

  # CI-003: Docker build validation
  docker-build:
    name: "Docker Build Validation"
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Build Docker image
        run: docker build -t dod-budget-test .

      - name: Validate Docker image imports
        run: |
          docker run --rm dod-budget-test python -c "from api.app import create_app; print('Import OK')"

  # DONE [Group: BEAR] BEAR-007: Deploy workflow template created at .github/workflows/deploy.yml
